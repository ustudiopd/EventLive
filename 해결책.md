요약부터 말씀드릴게요.

* **정상 시나리오:** Supabase Realtime(WebSocket)이 **항상 연결**되고, 새 메시지는 `postgres_changes` 이벤트로 푸시됩니다. 폴백 폴링은 진짜 문제가 있을 때만 **잠깐** 쓰는 비상용입니다.
* **지금 상황:** 콘솔의 `실시간 구독 상태: CLOSED undefined`가 반복 → 3회 재시도 후 **항상 폴백으로 전환** → Vercel 함수 호출 수 폭증 & 메모리/CPU 낭비.
* **판단:** “Supabase stream으로 구현했는데 계속 폴링으로 간다”는 건 **정상 동작이 아닙니다.** 원인 수정을 통해 WebSocket 연결을 안정화해야 해요.

아래 체크리스트 순서대로 처리하면, 폴백 없이 **지속적인 Realtime**만으로 돌아가고 비용/부하가 급감합니다.

---

## 0) 즉시 완화(바로 적용)

1. **폴링 API에 캐시 헤더 추가** (있다면 유지)
   서버가 매번 깨어나는 걸 막습니다. (Vercel CDN이 응답)

```ts
// route.ts (GET /messages)
return NextResponse.json(payload, {
  headers: {
    'Cache-Control': 'public, s-maxage=1, stale-while-revalidate=9'
  }
})
```

2. **폴링 주기 완화**
   비상 폴링은 최소 8–10초 이상으로. 3초는 서버리스 과금 모델과 상극입니다.

> 위 둘만으로도 부하가 즉시 내려갑니다. 하지만 근본 해결은 아래 1–3번입니다.

---

## 1) WebSocket(Realtime) “연결” 자체 점검

대부분 여기서 막힙니다.

### A. Supabase URL이 “프로젝트 도메인(.supabase.co)”인지 확인

커스텀 프록시 도메인(예: `https://must.ai.kr`)을 `createClient`에 넣으면, Realtime의 `wss://<domain>/realtime/v1`로 붙는데 **역프록시 설정**이 완벽하지 않으면 **Handshake 실패 → `CLOSED` 반복**이 납니다.

> **정답:** 브라우저 클라이언트에는 반드시 프로젝트 도메인 사용

```ts
// lib/supabase/browser.ts
export const createBrowserClient = () =>
  createClient(
    process.env.NEXT_PUBLIC_SUPABASE_URL!,      // https://<project-ref>.supabase.co
    process.env.NEXT_PUBLIC_SUPABASE_ANON_KEY!, // anon 키 (절대 service_role 아님)
    { auth: { persistSession: true } }
  )
```

앱의 **자체 도메인**(ex. must.ai.kr)은 “앱 페이지 호스팅용”이고, Supabase 클라이언트의 `URL`은 **`.supabase.co`** 이어야 합니다.

### B. 브라우저(클라이언트 컴포넌트)에서만 구독

SSR/Route Handler/Edge Runtime에서 채널을 만들면 **연결이 유지되지 못하고 바로 닫힙니다**.
`use client` 컴포넌트에서만 `channel()`을 만들고, `useEffect`로 수명 관리하세요.

```tsx
'use client'
const channelRef = useRef<RealtimeChannel | null>(null)

useEffect(() => {
  // 기존 채널 정리 (중복 가입 방지)
  if (channelRef.current) supabase.removeChannel(channelRef.current)

  const ch = supabase
    .channel(`msg:${webinarId}`)
    .on('postgres_changes', {
      event: 'INSERT',
      schema: 'public',
      table: 'messages',
      filter: `webinar_id=eq.${webinarId}`,
    }, (payload) => setMessages(prev => [...prev, payload.new]))
    .subscribe((status, err) => {
      if (status === 'SUBSCRIBED') console.log('realtime ready')
      if (status === 'CHANNEL_ERROR') console.error('channel error', err)
      if (status === 'TIMED_OUT') console.warn('realtime timeout')
      if (status === 'CLOSED') console.warn('realtime closed', err)
    })

  channelRef.current = ch
  return () => { supabase.removeChannel(ch) }
}, [webinarId])
```

### C. 연결 원인코드 로깅(디버그)

지금 `CLOSED undefined`만 보이니 코드/사유를 찍어보세요.

```ts
supabase.realtime.onOpen(e => console.log('RT open', e))
supabase.realtime.onError(e => console.error('RT error', e))
supabase.realtime.onClose(e => console.warn('RT close', e?.code, e?.reason))
```

DevTools → **Network → WS → `/realtime/v1`** 프레임에서 **Close Code(1006/1008 등)**, **Response Headers**도 반드시 확인.

---

## 2) Realtime 전달 “권한/설정” 점검

### A. Publication(Replication)에 `messages` 포함

Supabase 대시보드 → Database → Replication → **Publications**에서
`messages` 테이블이 `supabase_realtime` 퍼블리케이션에 포함되어야 `postgres_changes`가 옵니다.

### B. RLS 정책 확인

Realtime도 RLS를 존중합니다. 해당 유저가 **그 webinar의 메시지를 SELECT 가능**해야 이벤트가 전달됩니다.
정책 필터가 너무 빡세면 “연결은 열리지만 이벤트가 안 옴” 현상도 생깁니다.

> 참고로, 현재 프로젝트에서 **profiles RLS 순환참조 이슈**로 500이 났던 사례가 있습니다. 권한/정책이 꼬이면 전반적인 인증 흐름에 부하와 실패가 불어납니다. 이 부분은 **클라이언트에서 직접 `profiles` 조회 제거 + 서버에서만 권한 확인**으로 우회/수정 권장되어 있습니다. 

### C. 인증 토큰 & 키 종류

* 브라우저는 **anon key**만 사용 (절대 service_role 노출 금지)
* 세션이 자주 끊기면 Realtime가 **재인증**에 실패해 닫힐 수 있으니, `persistSession: true`와 **리프레시 토큰 흐름**을 최신 `@supabase/supabase-js`로 유지하세요.

---

## 3) 구독 로직 “중복/루프” 방지

`useEffect` 의존성에 `messages` 같은 상태를 넣으면, 새 이벤트마다 **재구독 → 해제 → 재구독**의 무한 루프가 납니다.
**의존성은 `webinarId` 정도로 한정**하고, 이전 채널은 `removeChannel`로 확실히 정리하세요(위 예시 코드 참고).

또한 페이지 이동/탭 중복으로 채널이 여러 개 생기면 서버도 불필요한 리소스를 씁니다. `channelRef` 한 개만 유지하면 됩니다.

---

## 4) 폴백 폴링을 “값 싸게” 만드는 방법 (문제 해결 전 임시)

* **캐시 헤더**(s-maxage + SWR)로 CDN 응답 유도(위 0번 참조)
* **조건부 요청**(ETag/If-None-Match)로 304 활용:

  ```ts
  // 서버: 가장 오래된 message id 혹은 updated_at으로 ETag 구성
  const etag = lastMessageIdOrUpdatedAt
  headers.set('ETag', etag)

  // 클라이언트: fetch 시 If-None-Match 전송, 304면 렌더 스킵
  ```
* **폴링 최소 8–10초** + **가시 스크롤 구간에서만** 로드(상단 “이전 대화 더보기” 버튼 방식 유지)

이렇게 하면, Realtime가 잠시 죽어도 함수 호출이 **천분의 일 수준**으로 내려가 비용 폭탄을 피합니다.

---

## 5) 최종 점검 체크리스트 (요약)

1. **NEXT_PUBLIC_SUPABASE_URL = `https://<project-ref>.supabase.co`** (커스텀 도메인 금지)
2. 구독은 **클라이언트 컴포넌트**에서만, `useEffect([webinarId])` / `removeChannel` 정리
3. **Publication에 `messages` 포함**, **RLS 정책**이 대상 유저의 SELECT 허용
4. **anon key** 사용 + 최신 `@supabase/supabase-js` + 세션 지속
5. 폴백 폴링은 **느리게** + **CDN 캐시/ETag**로 값 싸게

---

### 결론

* **Supabase Realtime 기반 채팅은 맞는 선택**입니다.
* 다만 지금은 **Realtime 연결 자체가 닫히면서** 폴백이 상시 켜져 부하가 커진 상태예요.
* 위 1) URL/런타임, 2) Publication/RLS, 3) 구독 수명 관리를 적용하면 폴백이 사실상 필요 없어지고, 호출/메모리/CPU가 급격히 안정화됩니다.

필요하시면, 현재 `createClient`/구독 훅/폴백 모듈의 코드를 **위 체크리스트 기준으로 리팩터링 버전**으로 바로 정리해 드릴게요.
